/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
2023-04-12 15:21:44 - root - INFO: - Dataset:Caltech101-20
2023-04-12 15:21:44 - root - INFO: - Prediction={
2023-04-12 15:21:44 - root - INFO: -           arch1 = [128, 256, 128]
2023-04-12 15:21:44 - root - INFO: -           arch2 = [128, 256, 128]
2023-04-12 15:21:44 - root - INFO: - Autoencoder={
2023-04-12 15:21:44 - root - INFO: -           arch1 = [1984, 1024, 1024, 1024, 128]
2023-04-12 15:21:44 - root - INFO: -           arch2 = [512, 1024, 1024, 1024, 128]
2023-04-12 15:21:44 - root - INFO: -           activations1 = relu
2023-04-12 15:21:44 - root - INFO: -           activations2 = relu
2023-04-12 15:21:44 - root - INFO: -           batchnorm = True
2023-04-12 15:21:44 - root - INFO: - training={
2023-04-12 15:21:44 - root - INFO: -           seed = 4
2023-04-12 15:21:44 - root - INFO: -           missing_rate = 0.5
2023-04-12 15:21:44 - root - INFO: -           start_dual_prediction = 100
2023-04-12 15:21:44 - root - INFO: -           batch_size = 256
2023-04-12 15:21:44 - root - INFO: -           epoch = 500
2023-04-12 15:21:44 - root - INFO: -           lr = 0.0001
2023-04-12 15:21:44 - root - INFO: -           alpha = 9
2023-04-12 15:21:44 - root - INFO: -           lambda1 = 0.1
2023-04-12 15:21:44 - root - INFO: -           lambda2 = 0.1
2023-04-12 15:21:44 - root - INFO: - print_num = 100
2023-04-12 15:21:44 - root - INFO: - dataset = Caltech101-20
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
2023-04-12 15:21:50 - root - INFO: - Autoencoder(
  (_encoder): Sequential(
    (0): Linear(in_features=1984, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=128, bias=True)
    (10): Softmax(dim=1)
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=1984, bias=True)
    (10): BatchNorm1d(1984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU()
  )
)
2023-04-12 15:21:50 - root - INFO: - Prediction(
  (_encoder): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=128, out_features=256, bias=True)
    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=256, bias=True)
    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=128, bias=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=128, out_features=128, bias=True)
    (7): Softmax(dim=1)
  )
)
2023-04-12 15:21:50 - root - INFO: - Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)
2023-04-12 15:21:58 - root - INFO: - [2;29mEpoch : 100/500 ===> Reconstruction loss = 0.2813===> Reconstruction loss = 0.0256 ===> Dual prediction loss = 0.0186  ===> Contrastive loss = -4.4785e+02 ===> Loss = -4.4782e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:21:59 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6444, 'NMI': 0.6581, 'ARI': 0.6707, 'accuracy': 0.6702, 'precision': 0.5741, 'recall': 0.4682, 'f_measure': 0.4978}}[0m
2023-04-12 15:22:07 - root - INFO: - [2;29mEpoch : 200/500 ===> Reconstruction loss = 0.2505===> Reconstruction loss = 0.0204 ===> Dual prediction loss = 0.0011  ===> Contrastive loss = -4.4911e+02 ===> Loss = -4.4908e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:22:07 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.7103, 'NMI': 0.7367, 'ARI': 0.9069, 'accuracy': 0.7967, 'precision': 0.5871, 'recall': 0.5344, 'f_measure': 0.5403}}[0m
2023-04-12 15:22:16 - root - INFO: - [2;29mEpoch : 300/500 ===> Reconstruction loss = 0.2416===> Reconstruction loss = 0.0231 ===> Dual prediction loss = 0.0007  ===> Contrastive loss = -4.4839e+02 ===> Loss = -4.4836e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:22:16 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.7096, 'NMI': 0.7376, 'ARI': 0.9046, 'accuracy': 0.7976, 'precision': 0.5749, 'recall': 0.5335, 'f_measure': 0.5313}}[0m
2023-04-12 15:22:24 - root - INFO: - [2;29mEpoch : 400/500 ===> Reconstruction loss = 0.2280===> Reconstruction loss = 0.0201 ===> Dual prediction loss = 0.0010  ===> Contrastive loss = -4.4840e+02 ===> Loss = -4.4838e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:22:25 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.7092, 'NMI': 0.7386, 'ARI': 0.9055, 'accuracy': 0.8013, 'precision': 0.5732, 'recall': 0.5402, 'f_measure': 0.534}}[0m
2023-04-12 15:22:35 - root - INFO: - [2;29mEpoch : 500/500 ===> Reconstruction loss = 0.2159===> Reconstruction loss = 0.0192 ===> Dual prediction loss = 0.0007  ===> Contrastive loss = -4.4844e+02 ===> Loss = -4.4842e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:22:35 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.7086, 'NMI': 0.7362, 'ARI': 0.904, 'accuracy': 0.798, 'precision': 0.5685, 'recall': 0.5356, 'f_measure': 0.5323}}[0m
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
2023-04-12 15:22:35 - root - INFO: - Autoencoder(
  (_encoder): Sequential(
    (0): Linear(in_features=1984, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=128, bias=True)
    (10): Softmax(dim=1)
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=1984, bias=True)
    (10): BatchNorm1d(1984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU()
  )
)
2023-04-12 15:22:35 - root - INFO: - Prediction(
  (_encoder): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=128, out_features=256, bias=True)
    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=256, bias=True)
    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=128, bias=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=128, out_features=128, bias=True)
    (7): Softmax(dim=1)
  )
)
2023-04-12 15:22:35 - root - INFO: - Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)
2023-04-12 15:22:42 - root - INFO: - [2;29mEpoch : 100/500 ===> Reconstruction loss = 0.2843===> Reconstruction loss = 0.0271 ===> Dual prediction loss = 0.0198  ===> Contrastive loss = -4.4824e+02 ===> Loss = -4.4821e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:22:42 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.554, 'NMI': 0.5792, 'ARI': 0.4072, 'accuracy': 0.5184, 'precision': 0.4563, 'recall': 0.3846, 'f_measure': 0.384}}[0m
2023-04-12 15:22:50 - root - INFO: - [2;29mEpoch : 200/500 ===> Reconstruction loss = 0.2598===> Reconstruction loss = 0.0227 ===> Dual prediction loss = 0.0016  ===> Contrastive loss = -4.4978e+02 ===> Loss = -4.4975e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:22:51 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6303, 'NMI': 0.6522, 'ARI': 0.6068, 'accuracy': 0.5981, 'precision': 0.4888, 'recall': 0.4091, 'f_measure': 0.4226}}[0m
2023-04-12 15:23:01 - root - INFO: - [2;29mEpoch : 300/500 ===> Reconstruction loss = 0.2381===> Reconstruction loss = 0.0212 ===> Dual prediction loss = 0.0007  ===> Contrastive loss = -4.4901e+02 ===> Loss = -4.4898e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:23:02 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6308, 'NMI': 0.6521, 'ARI': 0.6065, 'accuracy': 0.6006, 'precision': 0.4814, 'recall': 0.3982, 'f_measure': 0.4179}}[0m
2023-04-12 15:23:12 - root - INFO: - [2;29mEpoch : 400/500 ===> Reconstruction loss = 0.2254===> Reconstruction loss = 0.0206 ===> Dual prediction loss = 0.0007  ===> Contrastive loss = -4.4935e+02 ===> Loss = -4.4933e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:23:12 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6426, 'NMI': 0.6623, 'ARI': 0.608, 'accuracy': 0.6085, 'precision': 0.4896, 'recall': 0.4285, 'f_measure': 0.4309}}[0m
2023-04-12 15:23:20 - root - INFO: - [2;29mEpoch : 500/500 ===> Reconstruction loss = 0.2184===> Reconstruction loss = 0.0198 ===> Dual prediction loss = 0.0013  ===> Contrastive loss = -4.4992e+02 ===> Loss = -4.4990e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:23:21 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6403, 'NMI': 0.6584, 'ARI': 0.6084, 'accuracy': 0.6073, 'precision': 0.4772, 'recall': 0.4114, 'f_measure': 0.4196}}[0m
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
2023-04-12 15:23:21 - root - INFO: - Autoencoder(
  (_encoder): Sequential(
    (0): Linear(in_features=1984, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=128, bias=True)
    (10): Softmax(dim=1)
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=1984, bias=True)
    (10): BatchNorm1d(1984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU()
  )
)
2023-04-12 15:23:21 - root - INFO: - Prediction(
  (_encoder): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=128, out_features=256, bias=True)
    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=256, bias=True)
    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=128, bias=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=128, out_features=128, bias=True)
    (7): Softmax(dim=1)
  )
)
2023-04-12 15:23:21 - root - INFO: - Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)
2023-04-12 15:23:27 - root - INFO: - [2;29mEpoch : 100/500 ===> Reconstruction loss = 0.2818===> Reconstruction loss = 0.0245 ===> Dual prediction loss = 0.0164  ===> Contrastive loss = -4.4778e+02 ===> Loss = -4.4775e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:23:28 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6157, 'NMI': 0.6341, 'ARI': 0.68, 'accuracy': 0.6337, 'precision': 0.4572, 'recall': 0.4138, 'f_measure': 0.4122}}[0m
2023-04-12 15:23:36 - root - INFO: - [2;29mEpoch : 200/500 ===> Reconstruction loss = 0.2563===> Reconstruction loss = 0.0211 ===> Dual prediction loss = 0.0010  ===> Contrastive loss = -4.4839e+02 ===> Loss = -4.4836e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:23:36 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.7075, 'NMI': 0.7322, 'ARI': 0.913, 'accuracy': 0.7787, 'precision': 0.5061, 'recall': 0.4981, 'f_measure': 0.4795}}[0m
2023-04-12 15:23:44 - root - INFO: - [2;29mEpoch : 300/500 ===> Reconstruction loss = 0.2479===> Reconstruction loss = 0.0228 ===> Dual prediction loss = 0.0013  ===> Contrastive loss = -4.4803e+02 ===> Loss = -4.4800e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:23:45 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.673, 'NMI': 0.7161, 'ARI': 0.8753, 'accuracy': 0.7611, 'precision': 0.464, 'recall': 0.4588, 'f_measure': 0.4394}}[0m
2023-04-12 15:23:53 - root - INFO: - [2;29mEpoch : 400/500 ===> Reconstruction loss = 0.2383===> Reconstruction loss = 0.0185 ===> Dual prediction loss = 0.0011  ===> Contrastive loss = -4.4864e+02 ===> Loss = -4.4861e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:23:53 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6718, 'NMI': 0.7198, 'ARI': 0.8738, 'accuracy': 0.7586, 'precision': 0.4548, 'recall': 0.4515, 'f_measure': 0.4217}}[0m
2023-04-12 15:24:01 - root - INFO: - [2;29mEpoch : 500/500 ===> Reconstruction loss = 0.2253===> Reconstruction loss = 0.0236 ===> Dual prediction loss = 0.0013  ===> Contrastive loss = -4.4732e+02 ===> Loss = -4.4730e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:24:02 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6721, 'NMI': 0.719, 'ARI': 0.8712, 'accuracy': 0.7607, 'precision': 0.5099, 'recall': 0.4558, 'f_measure': 0.4298}}[0m
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
2023-04-12 15:24:02 - root - INFO: - Autoencoder(
  (_encoder): Sequential(
    (0): Linear(in_features=1984, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=128, bias=True)
    (10): Softmax(dim=1)
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=1984, bias=True)
    (10): BatchNorm1d(1984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU()
  )
)
2023-04-12 15:24:02 - root - INFO: - Prediction(
  (_encoder): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=128, out_features=256, bias=True)
    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=256, bias=True)
    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=128, bias=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=128, out_features=128, bias=True)
    (7): Softmax(dim=1)
  )
)
2023-04-12 15:24:02 - root - INFO: - Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)
2023-04-12 15:24:08 - root - INFO: - [2;29mEpoch : 100/500 ===> Reconstruction loss = 0.2814===> Reconstruction loss = 0.0260 ===> Dual prediction loss = 0.0179  ===> Contrastive loss = -4.4764e+02 ===> Loss = -4.4761e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:24:09 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.5698, 'NMI': 0.6, 'ARI': 0.482, 'accuracy': 0.5436, 'precision': 0.5112, 'recall': 0.4052, 'f_measure': 0.4146}}[0m
2023-04-12 15:24:19 - root - INFO: - [2;29mEpoch : 200/500 ===> Reconstruction loss = 0.2619===> Reconstruction loss = 0.0239 ===> Dual prediction loss = 0.0008  ===> Contrastive loss = -4.4930e+02 ===> Loss = -4.4927e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:24:19 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6789, 'NMI': 0.6901, 'ARI': 0.7439, 'accuracy': 0.694, 'precision': 0.5156, 'recall': 0.4471, 'f_measure': 0.4511}}[0m
2023-04-12 15:24:27 - root - INFO: - [2;29mEpoch : 300/500 ===> Reconstruction loss = 0.2450===> Reconstruction loss = 0.0228 ===> Dual prediction loss = 0.0003  ===> Contrastive loss = -4.4923e+02 ===> Loss = -4.4920e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:24:28 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6862, 'NMI': 0.6983, 'ARI': 0.7479, 'accuracy': 0.6953, 'precision': 0.5319, 'recall': 0.4558, 'f_measure': 0.457}}[0m
2023-04-12 15:24:36 - root - INFO: - [2;29mEpoch : 400/500 ===> Reconstruction loss = 0.2373===> Reconstruction loss = 0.0210 ===> Dual prediction loss = 0.0007  ===> Contrastive loss = -4.4779e+02 ===> Loss = -4.4777e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:24:36 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6899, 'NMI': 0.7016, 'ARI': 0.7451, 'accuracy': 0.7024, 'precision': 0.5339, 'recall': 0.4689, 'f_measure': 0.4735}}[0m
2023-04-12 15:24:44 - root - INFO: - [2;29mEpoch : 500/500 ===> Reconstruction loss = 0.2270===> Reconstruction loss = 0.0235 ===> Dual prediction loss = 0.0010  ===> Contrastive loss = -4.4803e+02 ===> Loss = -4.4800e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:24:45 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6888, 'NMI': 0.7013, 'ARI': 0.7446, 'accuracy': 0.7058, 'precision': 0.532, 'recall': 0.4746, 'f_measure': 0.4784}}[0m
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
If you want the future behaviour and silence this warning, you can specify "categories='auto'".
In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
  warnings.warn(msg, FutureWarning)
2023-04-12 15:24:45 - root - INFO: - Autoencoder(
  (_encoder): Sequential(
    (0): Linear(in_features=1984, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=128, bias=True)
    (10): Softmax(dim=1)
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=1984, bias=True)
    (10): BatchNorm1d(1984, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU()
  )
)
2023-04-12 15:24:45 - root - INFO: - Prediction(
  (_encoder): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=128, out_features=256, bias=True)
    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (_decoder): Sequential(
    (0): Linear(in_features=128, out_features=256, bias=True)
    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Linear(in_features=256, out_features=128, bias=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Linear(in_features=128, out_features=128, bias=True)
    (7): Softmax(dim=1)
  )
)
2023-04-12 15:24:45 - root - INFO: - Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)
2023-04-12 15:24:52 - root - INFO: - [2;29mEpoch : 100/500 ===> Reconstruction loss = 0.2854===> Reconstruction loss = 0.0275 ===> Dual prediction loss = 0.0164  ===> Contrastive loss = -4.4719e+02 ===> Loss = -4.4716e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:24:52 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.5693, 'NMI': 0.5925, 'ARI': 0.6164, 'accuracy': 0.5834, 'precision': 0.4159, 'recall': 0.3689, 'f_measure': 0.3751}}[0m
2023-04-12 15:25:00 - root - INFO: - [2;29mEpoch : 200/500 ===> Reconstruction loss = 0.2675===> Reconstruction loss = 0.0227 ===> Dual prediction loss = 0.0013  ===> Contrastive loss = -4.4807e+02 ===> Loss = -4.4804e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:25:01 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6738, 'NMI': 0.7039, 'ARI': 0.8918, 'accuracy': 0.7515, 'precision': 0.4649, 'recall': 0.4704, 'f_measure': 0.4363}}[0m
2023-04-12 15:25:09 - root - INFO: - [2;29mEpoch : 300/500 ===> Reconstruction loss = 0.2550===> Reconstruction loss = 0.0207 ===> Dual prediction loss = 0.0007  ===> Contrastive loss = -4.4841e+02 ===> Loss = -4.4839e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:25:09 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.673, 'NMI': 0.704, 'ARI': 0.888, 'accuracy': 0.749, 'precision': 0.4566, 'recall': 0.4581, 'f_measure': 0.4329}}[0m
2023-04-12 15:25:17 - root - INFO: - [2;29mEpoch : 400/500 ===> Reconstruction loss = 0.2469===> Reconstruction loss = 0.0204 ===> Dual prediction loss = 0.0005  ===> Contrastive loss = -4.4861e+02 ===> Loss = -4.4858e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:25:18 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6756, 'NMI': 0.7118, 'ARI': 0.8888, 'accuracy': 0.7515, 'precision': 0.4371, 'recall': 0.4698, 'f_measure': 0.4253}}[0m
2023-04-12 15:25:26 - root - INFO: - [2;29mEpoch : 500/500 ===> Reconstruction loss = 0.2392===> Reconstruction loss = 0.0200 ===> Dual prediction loss = 0.0007  ===> Contrastive loss = -4.4848e+02 ===> Loss = -4.4845e+02[0m
/work/zhuyifan/2021-CVPR-Completer/model.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x).cuda()
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.
  FutureWarning)
/share/software/languages/ANACONDA/5.3_py3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.
  FutureWarning)
2023-04-12 15:25:26 - root - INFO: - [2;29mview_concat {'kmeans': {'AMI': 0.6733, 'NMI': 0.7041, 'ARI': 0.8896, 'accuracy': 0.7464, 'precision': 0.4392, 'recall': 0.4629, 'f_measure': 0.4237}}[0m
2023-04-12 15:25:26 - root - INFO: - --------------------Training over--------------------
2023-04-12 15:25:26 - root - INFO: - ACC:[0.798, 0.6073, 0.7607, 0.7058, 0.7464]
2023-04-12 15:25:26 - root - INFO: - NMI:[0.7362, 0.6584, 0.719, 0.7013, 0.7041]
2023-04-12 15:25:26 - root - INFO: - ARI:[0.904, 0.6084, 0.8712, 0.7446, 0.8896]
2023-04-12 15:25:26 - root - INFO: -  ACC 72.36 std 6.52 NMI 70.38 std 2.59 ARI 80.36 std 11.28
